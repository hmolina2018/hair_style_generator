{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"hairStyleGenerator.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"3SOJgRQv1ZCX","colab_type":"code","outputId":"976c74c2-2945-4d5b-cff9-e96ad4622b6d","executionInfo":{"status":"ok","timestamp":1568491115164,"user_tz":240,"elapsed":26845,"user":{"displayName":"Jose Manuel Arandia luna","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDrXfh9JBDpXu4-xd-mfrgMu0QKIP0oxYdlUiDwug=s64","userId":"02568312430588769187"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Wowwo1-L_DYQ","colab_type":"code","outputId":"a21585f4-6510-4144-e95e-394c72e92e4c","executionInfo":{"status":"ok","timestamp":1568491115170,"user_tz":240,"elapsed":26837,"user":{"displayName":"Jose Manuel Arandia luna","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDrXfh9JBDpXu4-xd-mfrgMu0QKIP0oxYdlUiDwug=s64","userId":"02568312430588769187"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%tensorflow_version 2.x"],"execution_count":2,"outputs":[{"output_type":"stream","text":["TensorFlow 2.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VOni3iHN4SNw","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z4RSqh2u4_wW","colab_type":"code","colab":{}},"source":["WORKING_DIR = \"/content/drive/My Drive/pix2pix/jmamoon/hairstyle_filtered\"\n","\n","INPUT_DIR_NAME = \"/input\"\n","OUTPUT_DIR_NAME = \"/output\"\n","CHECKPOINTS_DIR_NAME = \"/checkpoints\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"d61mYJGo4cHK","colab_type":"code","colab":{}},"source":["INPUT_DIR = WORKING_DIR + INPUT_DIR_NAME\n","OUTPUT_DIR = WORKING_DIR + OUTPUT_DIR_NAME\n","CHECKPOINTS_DIR = WORKING_DIR + CHECKPOINTS_DIR_NAME"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YUpIYjphIBRu","colab_type":"code","colab":{}},"source":["def read_images(directory):\n","  images = !ls -1 \"{directory}\"\n","  return images"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vnnf_SOx4wkI","colab_type":"code","colab":{}},"source":["all_inputs = read_images(INPUT_DIR)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DbNBmIg26o1T","colab_type":"code","colab":{}},"source":["def slice_images(images, quantity):\n","  return np.copy(images[:quantity])\n","\n","def shuffle_images(images, seed=None):\n","  if seed is not None:\n","    np.random.seed(seed)\n","  np.random.shuffle(images)\n","\n","def calculate_training_size(total, percent):\n","  return round(total * percent)\n","\n","def slice_training_images(images, percent):\n","  total = len(images)\n","  size = calculate_training_size(total, percent)\n","  return images[:size]\n","\n","def slice_test_images(images, percent):\n","  total = len(images)\n","  size = calculate_training_size(total, percent)\n","  return images[size:total]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"L27rq1zOIKu9","colab_type":"code","colab":{}},"source":["DATA_SIZE = 500\n","TRAINING_PERCENT = 0.8\n","SHUFFLE_SEED = 37\n","\n","random_inputs = slice_images(all_inputs, DATA_SIZE)\n","shuffle_images(random_inputs, SHUFFLE_SEED)\n","\n","training_inputs = slice_training_images(random_inputs, TRAINING_PERCENT)\n","testing_inputs = slice_test_images(random_inputs, TRAINING_PERCENT)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"k0llnSFQbg1X","colab_type":"code","colab":{}},"source":["import random"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G-LAJ4yuIYlN","colab_type":"code","colab":{}},"source":["def resize_image(image, width, height):\n","  return tf.image.resize(image, [width, height])\n","\n","def resize_image_pair(input_image, output_image, height, width):\n","  input_image = resize_image(input_image, width, height)\n","  output_image = resize_image(output_image, width, height)\n","  return input_image, output_image\n","\n","def normalize_image(image):\n","  return (image / 127.5) - 1\n","\n","def normalize_image_pair(input_image, output_image):\n","  input_image = normalize_image(input_image)\n","  output_image = normalize_image(output_image)\n","  return input_image, output_image\n","\n","@tf.function\n","def random_jitter_image_pair(input_image, output_image, width, height, offset):\n","  new_width = width + offset\n","  new_height = height + offset\n","  input_image = resize_image(input_image, new_width, new_height)\n","  output_image = resize_image(output_image, new_width, new_height)\n","  \n","  stacked_image = tf.stack([input_image, output_image], axis = 0)\n","  cropped_stacked_image = tf.image.random_crop(stacked_image, size = [2, width, height, 3])\n","  input_image = cropped_stacked_image[0]\n","  output_image = cropped_stacked_image[1]\n","  \n","  if (random.randint(0, 100) / 100) > 0.5:\n","    input_image = tf.image.flip_left_right(input_image)\n","    output_image = tf.image.flip_left_right(output_image)\n","  \n","  return input_image, output_image\n","\n","def load_image_from_file_system(directory, filename):\n","  return tf.cast(tf.image.decode_jpeg(tf.io.read_file(directory + \"/\" + filename)), tf.float32)[..., :3]\n","\n","def load_image_pair(filename, width, height, random_jitter_offset = 0):\n","  input_image = load_image_from_file_system(INPUT_DIR, filename)\n","  output_image = load_image_from_file_system(OUTPUT_DIR, filename)\n","  \n","  input_image, output_image = resize_image_pair(input_image, output_image, height, width)\n","  \n","  if random_jitter_offset > 0:\n","    input_image, output_image = random_jitter_image_pair(input_image, output_image, width, height, random_jitter_offset)\n","  \n","  input_image, output_image = normalize_image_pair(input_image, output_image)\n","  \n","  return input_image, output_image\n","\n","def load_image_pair_for_training(filename, width, height):\n","  return load_image_pair(filename, width, height, 30)\n","\n","def load_image_pair_for_testing(filename, width, height):\n","  return load_image_pair(filename, width, height)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pGGytCzz1Cel","colab_type":"code","outputId":"bd84ee67-3a81-4285-fcd9-617ecc73191c","executionInfo":{"status":"ok","timestamp":1568491124038,"user_tz":240,"elapsed":35665,"user":{"displayName":"Jose Manuel Arandia luna","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDrXfh9JBDpXu4-xd-mfrgMu0QKIP0oxYdlUiDwug=s64","userId":"02568312430588769187"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["IMAGE_WIDTH = 256\n","IMAGE_HEIGHT = 256\n","\n","dataset_for_training = tf.data.Dataset.from_tensor_slices(training_inputs)\n","dataset_for_training = dataset_for_training.map(lambda training_input: load_image_pair_for_training(training_input, IMAGE_WIDTH, IMAGE_HEIGHT), num_parallel_calls = tf.data.experimental.AUTOTUNE)\n","dataset_for_training = dataset_for_training.batch(1)\n","\n","dataset_for_testing = tf.data.Dataset.from_tensor_slices(testing_inputs)\n","dataset_for_testing = dataset_for_testing.map(lambda testing_input: load_image_pair_for_testing(testing_input, IMAGE_WIDTH, IMAGE_HEIGHT), num_parallel_calls = tf.data.experimental.AUTOTUNE)\n","dataset_for_testing = dataset_for_testing.batch(1)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Entity <function <lambda> at 0x7ff60d206a60> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n","WARNING: Entity <function <lambda> at 0x7ff60d206a60> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n","WARNING:tensorflow:Entity <function random_jitter_image_pair at 0x7ff60d1b5a60> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING: Entity <function random_jitter_image_pair at 0x7ff60d1b5a60> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING:tensorflow:Entity <function <lambda> at 0x7ff60d206d90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n","WARNING: Entity <function <lambda> at 0x7ff60d206d90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wNK3WeFjrcDz","colab_type":"code","colab":{}},"source":["from tensorflow.keras import *\n","from tensorflow.keras.layers import *\n","\n","def downsample(filters, apply_batch_normalization = True):\n","  layer = Sequential()\n","  \n","  initializer = tf.random_normal_initializer(0, 0.02)\n","  \n","  layer.add(Conv2D(filters,\n","                   kernel_size = 4,\n","                   strides = 2,\n","                   padding = \"same\",\n","                   kernel_initializer = initializer,\n","                   use_bias = not apply_batch_normalization))\n","  \n","  if apply_batch_normalization:\n","    layer.add(BatchNormalization())\n","  \n","  layer.add(LeakyReLU())\n","  \n","  return layer\n","\n","def upsample(filters, apply_dropout = False):\n","  layer = Sequential()\n","  \n","  initializer = tf.random_normal_initializer(0, 0.02)\n","  \n","  layer.add(Conv2DTranspose(filters,\n","                            kernel_size = 4,\n","                            strides = 2,\n","                            padding = \"same\",\n","                            kernel_initializer = initializer,\n","                            use_bias = False))\n","  \n","  layer.add(BatchNormalization())\n","  \n","  if apply_dropout:\n","    layer.add(Dropout(0.5))\n","  \n","  layer.add(ReLU())\n","  \n","  return layer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uyzjm_uOuX0p","colab_type":"code","colab":{}},"source":["def Generator():\n","  inputs = tf.keras.layers.Input(shape = [None, None, 3])\n","  \n","  down_stack = [\n","      downsample(64, apply_batch_normalization = False),\n","      downsample(128),\n","      downsample(256),\n","      downsample(512),\n","      downsample(512),\n","      downsample(512),\n","      downsample(512),\n","      downsample(512),\n","  ]\n","  \n","  up_stack = [\n","      upsample(512, apply_dropout = True),\n","      upsample(512, apply_dropout = True),\n","      upsample(512, apply_dropout = True),\n","      upsample(512),\n","      upsample(256),\n","      upsample(128),\n","      upsample(64),\n","  ]\n","  \n","  initializer = tf.random_normal_initializer(0, 0.02)\n","  \n","  last = Conv2DTranspose(filters = 3,\n","                         kernel_size = 4,\n","                         strides = 2,\n","                         padding = \"same\",\n","                         kernel_initializer = initializer,\n","                         activation = \"tanh\")\n","  \n","  x = inputs\n","  s = []\n","  \n","  concat = Concatenate()\n","  \n","  for down in down_stack:\n","    x = down(x)\n","    s.append(x)\n","  \n","  s = reversed(s[:-1])\n","  \n","  for up, sk in zip(up_stack, s):\n","    x = up(x)\n","    x = concat([x, sk])\n","  \n","  last = last(x)\n","  \n","  return Model(inputs = inputs, outputs = last)\n","\n","ini_img = None\n","for a in dataset_for_training.take(1):\n","  ini_img = a\n","\n","\n","generator = Generator()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QeFm_48P5c88","colab_type":"code","colab":{}},"source":["def Discriminator():\n","  ini = Input(shape = [None, None, 3], name = \"input_img\")\n","  gen = Input(shape = [None, None, 3], name = \"gener_img\")\n","  \n","  con = concatenate([ini, gen])\n","  \n","  initializer = tf.random_normal_initializer(0, 0.02)\n","  \n","  down1 = downsample(64, apply_batch_normalization = False)(con)\n","  down2 = downsample(128)(down1)\n","  down3 = downsample(256)(down2)\n","  down4 = downsample(512)(down3)\n","  \n","  last = tf.keras.layers.Conv2D(filters = 1,\n","                               kernel_size = 4,\n","                               strides = 1,\n","                               kernel_initializer = initializer,\n","                               padding = \"same\")(down4)\n","  \n","  return tf.keras.Model(inputs = [ini, gen], outputs = last)\n","\n","discriminator = Discriminator()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"m_fzkWsP7dCB","colab_type":"code","colab":{}},"source":["loss_object = tf.keras.losses.BinaryCrossentropy(from_logits = True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NErRk6y37skZ","colab_type":"code","colab":{}},"source":["def discriminator_loss(disc_real_output, disc_generated_output):\n","  real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n","  generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n","  \n","  total_disc_loss = real_loss + generated_loss\n","  \n","  return total_disc_loss"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GQku0O3g8SZZ","colab_type":"code","colab":{}},"source":["LAMBDA = 100\n","\n","def generator_loss(disc_generated_output, gen_output, target):\n","  gen_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n","  l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n","  \n","  total_gen_loss = gen_loss + (LAMBDA * l1_loss)\n","  \n","  return total_gen_loss"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2CB5q-MY9T4C","colab_type":"code","colab":{}},"source":["import os\n","\n","generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n","discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n","\n","checkpoint_prefix = os.path.join(CHECKPOINTS_DIR, \"ckpt\")\n","checkpoint = tf.train.Checkpoint(generator_optimizer = generator_optimizer,\n","                                discriminator_optimizer = discriminator_optimizer,\n","                                generator = generator,\n","                                discriminator = discriminator)\n","\n","#checkpoint.restore(tf.train.latest_checkpoint(CHECKPOINTS_DIR_NAME)).assert_consumed() "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MPyJAeEW-4Gz","colab_type":"code","colab":{}},"source":["def generate_images(model, test_input, tar, save_filename = False, display_imgs = True, training = True):\n","  prediction = model(test_input, training)\n","  \n","  if save_filename:\n","    tf.keras.preprocessing.image.save_img(WORKING_DIR + save_filename + \".jpg\", prediction[0, ...])\n","  \n","  plt.figure(figsize = (10, 10))\n","  \n","  display_list = [test_input[0], tar[0], prediction[0]]\n","  title = [\"input image\", \"ground truth\", \"predicted image\"]\n","  \n","  if display_imgs:\n","    for i in range(3):\n","      plt.subplot(1, 3, i + 1)\n","      plt.title(title[i])\n","      plt.imshow(display_list[i] * 0.5 + 0.5)\n","      plt.axis(\"off\")\n","  \n","  plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"N1G-bo-OCqdv","colab_type":"code","colab":{}},"source":["@tf.function\n","def train_step(input_image, target):\n","  \n","  with tf.GradientTape() as gen_tape, tf.GradientTape() as discr_tape:\n","  \n","    output_image = generator(input_image, training = True)\n","\n","    output_gen_discr = discriminator([output_image, input_image], training = True)\n","\n","    output_trg_discr = discriminator([target, input_image], training = True)\n","\n","    disc_loss = discriminator_loss(output_trg_discr, output_gen_discr)\n","\n","    gen_loss = generator_loss(output_gen_discr, output_image, target)\n","\n","    generator_grads = gen_tape.gradient(gen_loss, generator.trainable_variables)\n","\n","    discriminator_grads = discr_tape.gradient(disc_loss, discriminator.trainable_variables)\n","\n","    generator_optimizer.apply_gradients(zip(generator_grads, generator.trainable_variables))\n","\n","    discriminator_optimizer.apply_gradients(zip(discriminator_grads, discriminator.trainable_variables))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-19dwHMaAsbL","colab_type":"code","colab":{}},"source":["from IPython.display import clear_output\n","\n","def train(dataset, epochs, current_epoch = 0):\n","  for epoch in range(epochs)[current_epoch:]:\n","    imgi = 0\n","    for input_image, target in dataset:\n","      print(\"epoch \" + str(epoch) + \" - train: \" + str(imgi) + \"/\" + str(len(training_inputs)))\n","      imgi += 1\n","      train_step(input_image, target)\n","    \n","      clear_output(wait = True)\n","    \n","    if (epoch + 1) %25 == 0:\n","      checkpoint.save(file_prefix = checkpoint_prefix)\n","\n","      imgi = 0\n","      for inp, tar in dataset_for_testing.take(5):\n","        generate_images(generator, inp, tar, \"/generated_training/\" + str(imgi) + \"_\" + str(epoch), display_imgs = True)\n","        imgi += 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"S31TlBh5F_b0","colab_type":"code","outputId":"a6efeef3-9559-42f1-ebe1-b169b8e1cbc9","executionInfo":{"status":"error","timestamp":1568500174087,"user_tz":240,"elapsed":2915,"user":{"displayName":"Jose Manuel Arandia luna","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDrXfh9JBDpXu4-xd-mfrgMu0QKIP0oxYdlUiDwug=s64","userId":"02568312430588769187"}},"colab":{"base_uri":"https://localhost:8080/","height":323}},"source":["train(dataset_for_training, 1000)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["epoch 339 - train: 176/277\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-a7e1c0331b69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_for_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-22-137ba4dd1183>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, epochs, current_epoch)\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" - train: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0mimgi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m       \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.0.0-rc0/python3.6/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    413\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.0.0-rc0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1820\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1822\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1824\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.0.0-rc0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.0.0-rc0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.0.0-rc0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/tensorflow-2.0.0-rc0/python3.6/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"vz25ZQBPVnqg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1M89Lq4kuAf1QlGDcX5RkeGwecRfwPUZJ"},"outputId":"d0f86754-232b-466a-d69f-8fc50022aecb","executionInfo":{"status":"ok","timestamp":1568500185644,"user_tz":240,"elapsed":9919,"user":{"displayName":"Jose Manuel Arandia luna","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDrXfh9JBDpXu4-xd-mfrgMu0QKIP0oxYdlUiDwug=s64","userId":"02568312430588769187"}}},"source":["imgi = 0\n","for inp, tar in dataset_for_testing.take(20):\n","  generate_images(generator, inp, tar, \"/generated_testing/testing_\" + str(imgi), display_imgs = True)\n","  imgi += 1\n","  "],"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"i6_APgVGEgWE","colab_type":"code","colab":{}},"source":["asdasd = 14\n"],"execution_count":0,"outputs":[]}]}